---
layout:  post
title: "Web scraping and webcomics"
comments:  true
published:  true
author: "Zach Burchill"
date: 2015-12-12 20:00:00
categories: ['web scraping',webcomics,python,threading,R]
output:
  html_document:
    mathjax:  default
    fig_caption:  true
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(png)
library(grid)
library(ggplot2)
library(xkcd)
```

I like learning statistical modeling. I like webcomics.  I 

It started with the thought: "Can I use statistical modelling to tell me when I should stop hoping a webcomic will keep updating?"  There are few feelings worse than returning to a comic week after week in the vain hope its creator will start releasing new strips again.

And while that model is still in the works, I've gotten my hands on a bunch of cool data in the meantime.

## Web scraping

In order to make a model, you generally need data to train it on.  Most webcomics don't have a downloadable R database of all their updates, so you'll have to get the data yourself.  You can click through potentially thousands of pages, recording the dates manually, or you can use **web scraping** to do it automatically.

If you use Python and want an incredibly easy-to-get-into web scraping tool, check out the Python module, [Beautiful Soup](http://www.crummy.com/software/BeautifulSoup/) (I used `bs4`). In a nutshell, it loads HTML pages and parses the elements into a tree automatically. Extracting, say, all the `img` tags on a page can be as simple as: `soup.find_all('img')`. Beautiful Soup is pretty simple to learn and the [documentation](http://www.crummy.com/software/BeautifulSoup/bs4/doc/) makes it a breeze. 

## Data

## Broodhollow updates: a story of an author's life

"Broodhollow."  The name sounds like a title that a moody fifteen-year-old would come up with, but it is **absolutely** my favorite webcomic. _**Ever.**_ _Broodhollow's_ art is beautiful and the story writing is some of the best I've ever read. One part comedy and two parts creeping horror, if the phrase "Tintin meets H.P. Lovecraft" appeals to you at all, [go read it right now](http://broodhollow.chainsawsuit.com/). If author Kris Straub can finish the comic with a _tenth_ of the talent he's exhibited so far, I'm confident this will go down as one of the great graphic novels of our generation.

```{r broodhollow_snippet, echo=FALSE, fig.width=6,fig.height=3.46}
brood_hollow_pic <- readPNG("/Users/zburchill/Desktop/broodhollow_snippet.png")
grid.raster(brood_hollow_pic)
```

<p class = "figcaption">A sample of Kris Staub's genius.</p>
 
That is, _if_ he can finish it. Kris is a [pretty prolific artist](http://studios.chainsawsuit.com/) and just had a child a couple of years ago.  While he's continued regular updates to his non-serial comedic strip, [Chainsawsuit](http://chainsawsuit.com/) (another one of my favorites, actually), Broodhollow has gone through a few hiatuses.

### The data

So let's actually look at how often _Broodhollow_ has been updating.

```{r broodhollow_graph,echo=FALSE,fig.width=10,warning=FALSE}
broodhollow<-read.csv("/Users/zburchill/Desktop/broodhollow_dates.csv")
broodhollow$Date <- as.Date(broodhollow$post_data,format="%m/%d/%y")
broodhollow$Diff <- c(NA,diff(broodhollow$Date))
broodhollow$cadavrelab <- factor(ifelse(broodhollow$cadavre=="True","Yes","No"))

segments <- data.frame(
  x=c(as.Date("09/15/12",format="%m/%d/%y"),
      as.Date("09/15/13",format="%m/%d/%y"),
      as.Date("06/15/15",format="%m/%d/%y")),
  xend=c(as.Date("07/23/13",format="%m/%d/%y"),
         as.Date("10/23/14",format="%m/%d/%y"),
         as.Date("11/01/16",format="%m/%d/%y")),
  y=c(10,10,25),
  yend=c(10,10,25)
)

text = data.frame(
  label=c("Book I","Book II","Book III"),
  x=c(as.Date("09/15/12",format="%m/%d/%y"),
      as.Date("09/15/13",format="%m/%d/%y"),
      as.Date("09/15/15",format="%m/%d/%y")),
  y=c(20,20,35)
)

broodhollow %>% 
  ggplot(aes(x=Date,y=abs(Diff),color=cadavrelab)) +
  geom_point(size=2) +
  ylab("# of days till next comic") +
  scale_color_discrete("Cadavre comic?") +
  ggtitle("Broodhollow update schedule") +
  geom_segment(data=segments,
               aes(x=x, xend=xend, y=y, yend=yend),
               color="black") + 
  geom_text(data=text,
            aes(x=x,y=y,label=label),
            hjust=0,color="black",
            size=8) +
  geom_segment(aes(x=as.Date("11/25/14",format="%m/%d/%y"),
                   xend=as.Date("05/15/15",format="%m/%d/%y"),
                   y=20,yend=20),
               color="#CE534D") +
  annotate(geom="text",label="first child born",
           y=30,x=as.Date("07/25/14",format="%m/%d/%y"),
           hjust=0,color="#CE534D",
           size=6) +
  theme_bw() +
  theme(text=element_text(size=20),
        legend.title=element_text(size=15),
        legend.text=element_text(size=10))
```

<p class = "figcaption">'Cadavre' comics are non-serial humorous strips about the daily life of a French-accented skeleton, generally consider filler material.</p>

I like this graph because it visually tells the story of the evolving involvement of the author with the comic. **Book I** of Broodhollow, "Curious Little Thing", has _very_ consistent updates, as evidenced by the tight line of updates.  **Book II**, "Angleworm", continues after a short rest, and updates are still _fairly_ regular, although you see there's definitely more variability. But then, BAM!  As they say, [a baby changes everything](https://www.youtube.com/watch?v=-y0_wNPSOaw&t=1m20s). After a long hiatus, *Book III* teeters to a start, with sporadic updates and lots of filler material.

To me, webcomics that fall into this pattern are the reason why I want a model to tell me if I should give up on them.  They keep toying with my hope that they will start updating like they were before.  But on the other hand, we can see that even though Book III updates less frequently, Kris hasn't forgotten about it. We'll need more data.

## SMBC: longer and more uncut

Unlike _Broodhollow_, _Saturday Morning Breakfast Cereal_ has no problems with regular updates. In a downright _freakish_ display of perseverance, _Saturday Morning Breakfast Cereal_ (or SMBC as its often known by) updates every. _Damn_. _**DAY**_.  [Zach Weinersmith](https://twitter.com/ZachWeiner) is a gangly, red-headed _beast_, and just by virtue of his update schedule, SMBC would remain one of my favorites.  

Early SMBC comics usually consisted of a single panel, and relied on a specific brand of humor to get laughs. To long-time readers of the comic, [my brother](https://twitter.com/andrewburchill) and I, it felt that a while ago Zach started doing longer and longer strips, which we joked got less and less funny.  So when I started collected data, my brother suggested that I collect data on how long his strips were at the same time. Were his strips _really_ getting longer, or was it just our imagination?

### The data

Combining the `Pillow` module for Python 3 with my web scraping code, I recorded the width and height of each of his comics.  Unlike many webcomics, I should add, SMBC generally is in "portrait" orientation, meaning that **the longer the comic, the taller the image**.

```{r smbc_graph,echo=FALSE,warning=FALSE,fig.width=10}
smbc<-read.csv("/Users/zburchill/Desktop/smbc_dates.csv")
smbc$Date <- as.Date(smbc$post_date,format="%m/%d/%y")
smbc$Diff <- c(NA,diff(smbc$Date))
smbc$Epoch <- as.numeric(smbc$Date)

smbc %>%
  ggplot(aes(x=Date,y=height)) +
  geom_point(alpha=0.2,size=3,color="#46433A") +
  ylab("height in pixels") +
  ggtitle("Height of SMBC comics over time") +
  stat_smooth(method="lm",
              formula=y~poly(x,4),color="#CE534D",size=2) +
  theme_bw() +
  theme(text=element_text(size=20),
        legend.title=element_text(size=15),
        legend.text=element_text(size=10)) +
  geom_point(aes(x=as.Date("2008-08-10"),y=1519),color="red")
```

<p class = "figcaption">It would seem that around late 2008, (<a href="http://www.smbc-comics.com/comic/2008-08-10">August 10th by my reckoning</a>, marked on the graph) Zach started getting bored with one-panel comic strips.</p>

I was surprised by how quickly SMBC started coming out with longer comics after late 2008. Clearly, once Zach tasted the sweet, sweet taste of multi-panel comics, he couldn't let it go.

Now, for a little bit of humor only Zach Weinersmith could find funny:

```{r smbc_votey_graph,warning=FALSE,echo=FALSE,fig.width=7,fig.height=5}
p <- smbc %>%
  ggplot(aes(x=as.numeric(Date),y=height)) +
  stat_smooth(aes(color="\nApprox. number\nof panels per comic\n"),
            #  method="loess",
              fill=NA) +
  stat_smooth(aes(x=as.numeric(Date),
                  y=-height+2000,
                  color="How funny SMBC is"),
             # method="loess",
              fill=NA) +
  ylab("") +
  scale_color_discrete(name="") +
  scale_y_continuous(labels=function(x) round(x/500)) +
  scale_x_continuous(name="",
                     breaks=c(as.numeric(as.Date("01/01/05",format="%m/%d/%y")),
                          as.numeric(as.Date("01/01/10",format="%m/%d/%y")),
                          as.numeric(as.Date("01/01/15",format="%m/%d/%y"))),
                 labels=c("2005","2010","2015")) +
  xkcdaxis(range(as.numeric(smbc$Date),na.rm=TRUE),c(-0.05,2000)) +
  theme(text = element_text(size = 20, family = "xkcd"),
        legend.text = element_text(size = 20, family = "xkcd"))

p = p + annotate(geom="text",label = "One \"panel\" = 500 px", x = Inf, y = 250, hjust = -0.25, family="xkcd",color="grey",size=7)

gt <- ggplot_gtable(ggplot_build(p))
gt$layout$clip[gt$layout$name == "panel"] <- "off"
grid.draw(gt)
```

<p class = "figcaption">Just kidding Zach, I know how much you appreciate graph jokes. Typical height of 1 panel $\approx$ 500 px. If you want to make graphs that look like this in `ggplot`, you can with the... `xkcd` package in R.</p>

## Prague Race:

## Source code:

> My multi-thread web-scraper

Written for Python 3.4+, requires Beautiful Soup and Pillow. If you have `pip` you can try: `python3 pip install beautifulsoup4` and `python3 pip install pillow`.  This is my first time ever working with threads in Python. Probably overkill, but it was fun to learn about. If you have any comments about what I could do better--any rookie mistakes I made--feel free to leave a comment... Once I get around to adding a comment section.

> My crappier, non-threaded, web-scraper with poor documentation

Also written for Python 3.4+, requires Beautiful Soup and Pillow. This is the earlier, crappier version of my code for a few of the examples, more or less.



