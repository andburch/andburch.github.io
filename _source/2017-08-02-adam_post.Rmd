---
layout:  post
title: "ADAM: the Adamesque porcelain keyboard"
comments:  true
published:  true
author: "Zach Burchill"
date: 2017-08-02 10:00:00
permalink: /adam_ic.html
categories: ['mechanical keyboards','3D printing','3D design','interest check',keyboard,porcelain]
output:
  html_document:
    mathjax:  default
    fig_caption:  true
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(png)
library(grid)
library(ggplot2)
library(xkcd)
# Set random seed so it doesn't keep redrawing the plots whenever I change anything
set.seed(123)
```

I like statistical models. I like webcomics. I like not having to suffer through deciding whether a webcomic is ever going to update regularly again. I began to ask myself, "Can I use statistical modelling to tell me when I should stop hoping a webcomic will keep updating?"

Nothing is more haunting than that oft-repeated phrase: "updates when?" It's not even about the wait, it's about the _uncertainty_--either end or start updating, don't keep me in limbo!  I would love it if I could make a model that could just _tell_ me, "Hey, this comic is entering its death spiral, abandon ship!"  Also, I just like learning new statistical methods.

Although that model is still in the works, I've gotten my hands on a bunch of cool data in the meantime.  This post isn't quite a tutorial; it's more like a demonstration of how you can fun with simple web scraping and niche interests--but I've attached all the code I used, complete with documentation and a flexible design for newbies who want to start collecting their own data.

<!--more-->

## Web scraping 101

In order to make a model, you generally need data to train it on.  Most webcomics don't have a downloadable R database of all their updates, so you'll have to get the data yourself.  You can click through potentially thousands of pages, recording the dates manually, or you can use **web scraping** to do it automatically[^1].

If you use Python and want an incredibly easy-to-get-into web scraping tool, check out the Python module, [Beautiful Soup](http://www.crummy.com/software/BeautifulSoup/) (I used `bs4`). In a nutshell, it loads HTML pages and parses the elements into a tree automatically. Extracting, say, all the `img` tags on a page can be as simple as: `soup.find_all('img')`. Beautiful Soup is pretty simple to learn and the [documentation](http://www.crummy.com/software/BeautifulSoup/bs4/doc/) makes it a breeze. Check my source code at the end for the code I used.

## Broodhollow updates: a story of an author's life

"Broodhollow."  The name sounds like a title that a moody fifteen-year-old would come up with, but it is **absolutely** my favorite webcomic. _**Ever.**_ _Broodhollow's_ art is beautiful and the story writing is some of the best I've ever read. One part comedy and two parts creeping horror, if the phrase "Tintin meets H.P. Lovecraft" appeals to you at all, [go read it right now](http://broodhollow.chainsawsuit.com/). If author Kris Straub can finish the comic with a _tenth_ of the talent he's exhibited so far, I'm confident this will go down as one of the great graphic novels of our generation.

```{r broodhollow_snippet, echo=FALSE, fig.width=6,fig.height=3.46}
brood_hollow_pic <- readPNG("/Users/zburchill/Desktop/white_keys_front_lol.png")
grid.raster(brood_hollow_pic)
```



<hr />
<br />

## Source Code:

> [`web_scraper_threaded_general.py`]({{ site.url }}/code/web-scraping/web_scraper_threaded_general.py)

My multi-thread web-scraper, written for Python 3.4+, requires Beautiful Soup and Pillow. If you have `pip` you can try: `python3 pip install beautifulsoup4` and `python3 pip install pillow`.  This is my first time ever working with threads in Python--probably overkill, but it was fun to learn about. If you have any comments about what I could do better--any rookie mistakes I made--feel free to leave a comment below.

> [`web_scraper_nonthreaded.py`]({{ site.url }}/code/web-scraping/web_scraper_nonthreaded.py)

My crappier, non-threaded, web-scraper with poor documentation. Also written for Python 3.4+, requires Beautiful Soup and Pillow. This is the earlier, crappier version of my code for a few of the examples, more or less.

> [`2016-11-14-webcomic_post.Rmd`]({{ site.url }}/_source/2016-11-14-webcomic_post.Rmd)

The R Markdown file this blog post is generated from, if you want to know what R code I used for the analysis and plotting.

### Footnotes

[^1]: I should point out, for pedantry's sake, that webcomics make _especially_ easy targets to web scrape, given their fairly consistent structure and general lack of JavaScript. Web scraping is a bit harder when you want to collect JavaScript-generated content--check out `PhantomJS` and `Selenium` Python libraries for good places to start.


